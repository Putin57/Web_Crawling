{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2304abb",
   "metadata": {},
   "source": [
    "### Web Crawler ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c462a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import requests\n",
    "import re\n",
    "import csv\n",
    "from html import unescape\n",
    "\n",
    "def get_category_list(content):\n",
    "    \"\"\"get_category_list() takes content of home page and returns\n",
    "    a list of categories and their urls\n",
    "    \"\"\"\n",
    "    return category_pat.findall(content)\n",
    "\n",
    "def get_book_list(content):\n",
    "    \"\"\"get_book_list() takes content of a book list page and returns\n",
    "    a list of books (name and url)\n",
    "    \"\"\"\n",
    "    content = content.replace(\"\\n\", \" \")\n",
    "    return book_list_pat.findall(content)\n",
    "\n",
    "def get_product_details(content):\n",
    "    \"\"\"get_product_details() takes content of a product page, parses\n",
    "    the page and returns details about a product\n",
    "    \"\"\"\n",
    "    image_base = \"http://books.toscrape.com/\"\n",
    "    result = img_pat.findall(content)\n",
    "    if len(result) == 0:\n",
    "        logging.warn(\"Image url not found!\")\n",
    "        image_url = \"\"\n",
    "    else:\n",
    "        img_url = result[0]\n",
    "        img_url = img_url.replace(\"../../\", \"\")\n",
    "        image_url = image_base + img_url\n",
    "    result = desc_pat.findall(content)\n",
    "    if len(result) == 0:\n",
    "        logging.warn(\"Description not found!\")\n",
    "        description = \"\"\n",
    "    else:\n",
    "        description = unescape(result[0])\n",
    "    result = upc_pat.findall(content)\n",
    "    if len(result) == 0:\n",
    "        logging.warn(\"UPC not found!\")\n",
    "        upc = \"\"\n",
    "    else:\n",
    "        upc = result[0]\n",
    "    result = price_pat.findall(content)\n",
    "    if len(result) == 0:\n",
    "        logging.warn(\"Price not found!\")\n",
    "        price = \"\"\n",
    "    else:\n",
    "        price = result[0]\n",
    "    result = avail_pat.findall(content)\n",
    "    if len(result) == 0:\n",
    "        logging.warn(\"Availability not found!\")\n",
    "        availability = \"\"\n",
    "    else:\n",
    "        availability = result[0]\n",
    "    return upc, price, image_url, availability, description\n",
    "\n",
    "def get_page_content(url):\n",
    "    \"\"\"get_page_content() takes a url and returns the content of the page\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(e)\n",
    "    if response.ok:\n",
    "        return response.text\n",
    "    logging.error(\"Can not get content from URL:\" + url)\n",
    "    return \"\"\n",
    "\n",
    "def get_next_page(url, content):\n",
    "    \"\"\"get_next_page() checks the content of a book list page and\n",
    "    returns link of  the next page, returns None, if there is no\n",
    "    more next page\n",
    "    \"\"\"\n",
    "    result = next_page_pat.findall(content)\n",
    "    if len(result) == 0:\n",
    "        return None\n",
    "    i = url.rfind(\"/\")\n",
    "    return url[0:i + 1] + result[0]\n",
    "\n",
    "def scrape_book_info(book_info, category_name):\n",
    "    \"\"\"scrape_book_info() gets the content of a book details page,\n",
    "    and parses different components and stores the info \"\"\"\n",
    "\n",
    "    book_url, book_name = book_info\n",
    "    book_name = unescape(book_name)\n",
    "    book_dict = {\"Name\": book_name, \"Category\": category_name}\n",
    "    book_url = book_url.replace(\"../../../\", \"\")\n",
    "    book_url = \"http://books.toscrape.com/catalogue/\" + book_url\n",
    "    book_dict[\"URL\"] = book_url\n",
    "    print(\"Scraping book\", book_name)\n",
    "    logging.info(\"Scraping : \" + book_url)\n",
    "    content = get_page_content(book_url)\n",
    "    content = content.replace(\"\\n\", \" \")\n",
    "    upc, price, image_url, availability, desc = get_product_details(content)\n",
    "    book_dict[\"UPC\"] = upc\n",
    "    book_dict[\"Price\"] = price\n",
    "    book_dict[\"ImageURL\"] = image_url\n",
    "    book_dict[\"Availability\"] = availability\n",
    "    book_dict[\"Description\"] = desc\n",
    "    csv_writer.writerow(book_dict)\n",
    "\n",
    "def crawl_category(category_name, category_url):\n",
    "    \"\"\"crawl_category() crawls a particular category of books\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        content = get_page_content(category_url)\n",
    "        book_list = get_book_list(content)\n",
    "        for book in book_list:\n",
    "            scrape_book_info(book, category_name)\n",
    "        next_page = get_next_page(category_url, content)\n",
    "        if next_page is None:\n",
    "            break\n",
    "        category_url = next_page\n",
    "\n",
    "def crawl_website():\n",
    "    \"\"\"crawl_website() is the main function that coordinates the whole crawling task\n",
    "    \"\"\"\n",
    "    url = \"http://books.toscrape.com/index.html\"\n",
    "    host_name = \"books.toscrape.com\"\n",
    "    content = get_page_content(url)\n",
    "    if content == \"\":\n",
    "        logging.critical(\"Got empty content from \" + url)\n",
    "        sys.exit(1)\n",
    "    category_list = get_category_list(content)\n",
    "    for category in category_list:\n",
    "        category_url, category_name = category\n",
    "        category_url = \"http://\" + host_name + \"/\" + category_url\n",
    "        crawl_category(category_name, category_url)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Compile different regular expression patterns\n",
    "    category_pat = re.compile(r'<li>\\s*<a href=\"(catalogue/category/books/.*?)\">\\s*(\\w+[\\s\\w]+\\w)\\s*?<',re.M | re.DOTALL)\n",
    "    next_page_pat = re.compile(r'<li class=\"next\"><a href=\"(.*?)\">next</a></li>')\n",
    "    book_list_pat = re.compile(r'<h3><a href=\"(.*?)\" title=\"(.*?)\">')\n",
    "    img_pat = re.compile(r'<div class=\"item active\">\\s*<img src=\"(.*?)\"')\n",
    "    desc_pat = re.compile(r'<div id=\"product_description\" class=\"sub-header\">.*?<p>(.*?)</p>')\n",
    "    upc_pat = re.compile(r'<th>UPC</th>\\s*<td>(.*?)</td>')\n",
    "    price_pat = re.compile(r'<th>Price \\(incl. tax\\)</th>\\s*<td>\\D+([\\d.]+?)</td>')\n",
    "    avail_pat = re.compile(r'<th>Availability</th>\\s*<td>(.*?)</td>')\n",
    "    logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p',filename=\"bookstore_crawler.log\", level=logging.DEBUG)\n",
    "    header_fields = [\"Name\", \"Category\", \"UPC\", \"URL\", \"ImageURL\",\"Price\", \"Availability\", \"Description\"]\n",
    "\n",
    "    with open(\"book_list.csv\", \"w\", encoding=\"ISO-8859-1\") as csvf:\n",
    "        csv_writer = csv.DictWriter(csvf, fieldnames=header_fields)\n",
    "        csv_writer.writeheader()\n",
    "        crawl_website()\n",
    "        print(\"Crawling Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
